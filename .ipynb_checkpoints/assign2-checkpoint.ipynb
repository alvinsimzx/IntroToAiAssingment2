{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "a9BnRgdxKjJK",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# installing packages\n",
    "# !pip install tensorflow\n",
    "# !pip install -q keras\n",
    "# !pip install opencv-python\n",
    "# !pip install matplotlib\n",
    "# !pip install tqdm\n",
    "# !pip install tensorflow-gpu\n",
    "!pip install scikit-plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "m6h2zNPAACUI"
   },
   "outputs": [],
   "source": [
    "# mounting drive from google drive\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "kkMcv4rXr_y4"
   },
   "outputs": [],
   "source": [
    "# Load the TensorBoard notebook extension\n",
    "%load_ext tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "NF6G_nDrOkgC"
   },
   "outputs": [],
   "source": [
    "# Libraries for random forest\n",
    "import matplotlib\n",
    "import math\n",
    "import scikitplot as skplt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from random import shuffle\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn import metrics\n",
    "\n",
    "# Libraries for creating training data\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "import os\n",
    "import random\n",
    "import pickle\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Libraries for creating model\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, Activation, Flatten\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D\n",
    "\n",
    "# Visuallize the training of the model (validation & accuracy loss)\n",
    "from tensorflow.keras.datasets import cifar10\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.callbacks import TensorBoard\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "KZJPQ4_fTgm1"
   },
   "outputs": [],
   "source": [
    "# Initializes the paths of the datasets\n",
    "TRAIN_DATA_DIR = \"images/JAFFESorted\" # Relative directory of the images folder\n",
    "#TRAIN_DATA_DIR = \"images/FEISorted\"\n",
    "#TRAIN_DATA_DIR = \"images/FEI+JAFFE\"\n",
    "TEST_DATA_DIR = \"images/Testing Data Suzy\"\n",
    "\n",
    "# Initializes the paths of the training pickles\n",
    "#\n",
    "# X pickles\n",
    "train_dir_X = \"pickle/X_JAFFE.pickle\"\n",
    "#train_dir_X = \"pickle/X_FEI.pickle\"\n",
    "#train_dir_X = \"pickle/X_FEI.pickle\"\n",
    "\n",
    "# y pickles\n",
    "train_dir_y = \"pickle/y_JAFFE.pickle\"\n",
    "#train_dir_y = \"pickle/y_FEI.pickle\"\n",
    "#train_dir_y = \"pickle/y_FEI_JAFFE.pickle\"\n",
    "\n",
    "# Initializes the paths of the test pickles\n",
    "test_dir_X = \"pickle/X_SUZY.pickle\"\n",
    "test_dir_y = \"pickle/y_SUZY.pickle\"\n",
    "\n",
    "CATEGORIES = [\"Good\", \"Bad\"] # Stores the output classifiers\n",
    "IMG_SIZE = 100 # Shape of img, 100 x 100 pixels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "hDGlPiZtGS57"
   },
   "outputs": [],
   "source": [
    "# Function to create training data\n",
    "# Returns training_data array\n",
    "def create_array_data(data_directory, categories, img_size):\n",
    "    array_data = []\n",
    "    \n",
    "    # The following loop iterates through all image paths, converts them to grayscale and stores them in an array\n",
    "    for category in categories:\n",
    "        path = os.path.join(data_directory, category)\n",
    "        class_num = categories.index(category) # Maps indices 0 or 1 for \"Good\" or \"Bad\"\n",
    "        for img in tqdm(os.listdir(path)):\n",
    "            try:\n",
    "                img_array = cv2.imread(os.path.join(path, img), cv2.IMREAD_GRAYSCALE) # Reads current img file, convert it to grayscale and stores them in img_array\n",
    "                new_array = cv2.resize(img_array, (img_size, img_size)) # Resizes img_array's resolution according to given img_size\n",
    "                array_data.append([new_array, class_num]) # Appends new image array to array_data\n",
    "            except Exception as e: # ignores errors from weird img files\n",
    "                pass\n",
    "    return array_data\n",
    "\n",
    "# Function to create pickle\n",
    "# void function\n",
    "def create_pickle_data(data_dir, categories, dir_X, dir_y, img_size):\n",
    "    # 50 : 50 ratio is the best, shuffling training data makes learning better\n",
    "    general_data = create_array_data(data_dir, categories, img_size) # create training/test data set\n",
    "    random.shuffle(general_data) # shuffles training/test dataset\n",
    "\n",
    "    # X is for feature set, y is for labels\n",
    "    # can specify validation set instead of splitting into x, y\n",
    "    X = []\n",
    "    y = []\n",
    "\n",
    "    for features, label in tqdm(general_data):\n",
    "        X.append(features)\n",
    "        y.append(label)\n",
    "        \n",
    "    # keras only accepts np arrays\n",
    "    X = np.array(X).reshape(-1, img_size, img_size, 1) # change 1 to 3 for pictures with colors\n",
    "    y = np.array(y)\n",
    "\n",
    "    # Exports data as pickle\n",
    "    pickle_out = open(dir_X, \"wb\")\n",
    "    pickle.dump(X, pickle_out)\n",
    "    pickle_out.close()\n",
    "\n",
    "    pickle_out = open(dir_y, \"wb\")\n",
    "    pickle.dump(y, pickle_out)\n",
    "    pickle_out.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "UPL7xFh0HdlM"
   },
   "outputs": [],
   "source": [
    "# Creates training pickle data\n",
    "create_pickle_data(TRAIN_DATA_DIR, CATEGORIES, train_dir_X, train_dir_y, IMG_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "FRmgF6XZKJ1K"
   },
   "outputs": [],
   "source": [
    "# Creates test pickle data\n",
    "create_pickle_data(TEST_DATA_DIR, CATEGORIES, test_dir_X, test_dir_y, IMG_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "UIDqj4LuGS6J"
   },
   "outputs": [],
   "source": [
    "# Loads data from pickle\n",
    "X_train = pickle.load(open(train_dir_X, \"rb\"))\n",
    "y_train = pickle.load(open(train_dir_y, \"rb\"))\n",
    "\n",
    "# Normalize data by scaling (changing pixel intensity values)\n",
    "# min value = 0, max value = 255 for pixels\n",
    "X_train = X_train/255.0\n",
    "\n",
    "# Loads data pickle\n",
    "X_test = pickle.load(open(test_dir_X, \"rb\"))\n",
    "y_test = pickle.load(open(test_dir_y, \"rb\"))\n",
    "\n",
    "# Normalize data by scaling (changing pixel intensity values)\n",
    "# min value = 0, max value = 255 for pixels\n",
    "X_test = X_test/255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "TLsqppNY-nQ7"
   },
   "outputs": [],
   "source": [
    "# Machine Learning\n",
    "# Random Forest Classifier\n",
    "\n",
    "# Initializing the classifier\n",
    "rfc = RandomForestClassifier(n_jobs=-1, n_estimators=35) #10,30,100\n",
    "X_train_rfc = X_train\n",
    "y_train_rfc = y_train\n",
    "X_test_rfc = X_test\n",
    "y_test_rfc = y_test\n",
    "\n",
    "# Fitting the model\n",
    "rfc.fit(X_train_rfc.reshape(len(X_train_rfc), -1), y_train_rfc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "gu6TcGM8AFxs"
   },
   "outputs": [],
   "source": [
    "rfc.score(X_test_rfc.reshape(len(X_test_rfc), -1), y_test_rfc)\n",
    "y_pred = rfc.predict(X_test_rfc.reshape(len(X_test_rfc), -1)) # obtain the RFC predictions and save into variale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "2bzgcP7yAXaY"
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize = (12,8)) #determine size of confusion matrix\n",
    "f,ax=plt.subplots(1, 1, figsize = (12,12))\n",
    "\n",
    "skplt.metrics.plot_confusion_matrix(y_test_rfc, y_pred, normalize = 'true', ax = ax) #plot the confusion matrix\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "lQMQt5KaBFpd"
   },
   "outputs": [],
   "source": [
    "from sklearn import svm \n",
    "\n",
    "model_svm = svm.SVC(gamma=\"scale\",C=5,kernel=\"sigmoid\") #use the Support vector classifier class \n",
    "model_svm.fit(X_train.reshape(len(X_train), -1),y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "L0ymZlpvCrvl"
   },
   "outputs": [],
   "source": [
    "#model_svm.score(X_test_rfc.reshape(len(X_test_rfc), -1), y_test_rfc)\n",
    "model_svm_labels_predict = model_svm.predict(X_test.reshape(len(X_test), -1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-YQ-YfnnDq1s"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_curve, auc,roc_auc_score\n",
    "\n",
    "fpr = dict()\n",
    "tpr = dict()\n",
    "roc_auc = dict()\n",
    "\n",
    "for i in range(2):\n",
    "    fpr[i], tpr[i], _ = roc_curve(y_test, model_svm_labels_predict)\n",
    "    roc_auc[i] = auc(fpr[i], tpr[i])\n",
    "\n",
    "print(\"Area under curve:\",roc_auc_score(y_test, model_svm_labels_predict))\n",
    "matplotlib.pyplot.figure()\n",
    "matplotlib.pyplot.plot(fpr[1], tpr[1])\n",
    "matplotlib.pyplot.xlim([0.0, 1.0])\n",
    "matplotlib.pyplot.ylim([0.0, 1.05])\n",
    "matplotlib.pyplot.xlabel('False Positive Rate')\n",
    "matplotlib.pyplot.ylabel('True Positive Rate')\n",
    "matplotlib.pyplot.title('Receiver operating characteristic')\n",
    "matplotlib.pyplot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "mMi_dOaP-B-p"
   },
   "outputs": [],
   "source": [
    "# Deep Learning\n",
    "# Convolutional Neural Network \n",
    "\n",
    "# Building the models\n",
    "dense_layers = [2]\n",
    "layer_sizes = [16]\n",
    "conv_layers = [2]\n",
    "filter_sizes = [3]\n",
    "dropout_values = [0.2]\n",
    "\n",
    "# Iterates through the arrays, generates layers or change values based on the array\n",
    "for dense_layer in dense_layers:\n",
    "    for layer_size in layer_sizes:\n",
    "        for conv_layer in conv_layers:\n",
    "            for filter_size in filter_sizes:\n",
    "                for dropout_value in dropout_values:\n",
    "                    # Log file name\n",
    "                    # tensorboard intialization for training visualization\n",
    "                    DATE = datetime.datetime.now().strftime(\"%Y/%m/%d-%H/%M/%S\")\n",
    "                    NAME = \"jaffe-{}-conv-{}-nodes-{}-dense-{}-filter_size-{}-dropout-{}\".format(conv_layer, layer_size, dense_layer, filter_size, dropout_value, DATE)\n",
    "                    logfolderdir = 'logs/jaffe/' # change directory to your pc\n",
    "                    logdir = logfolderdir + NAME\n",
    "                    tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=logdir, histogram_freq=1)\n",
    "\n",
    "                    print(\"\\n\" + NAME)\n",
    "                    \n",
    "                    # Building the model\n",
    "                    # Sequential is appropriate for a plain stack of layers where each layer has exactly one input tensor and one output tensor.\n",
    "                    model = Sequential()\n",
    "\n",
    "                    # Input image\n",
    "                    model.add(Conv2D(layer_size, (filter_size, filter_size), input_shape=X_train.shape[1:]))\n",
    "                    model.add(Activation('relu'))\n",
    "                    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "                    for layer in range(conv_layer - 1):\n",
    "                        model.add(Conv2D(layer_size, (filter_size, filter_size)))\n",
    "                        model.add(Activation('relu'))\n",
    "                        model.add(MaxPooling2D(pool_size = (2, 2)))\n",
    "\n",
    "                    model.add(Flatten())\n",
    "                    for layer in range(dense_layer):\n",
    "                        model.add(Dense(layer_size))\n",
    "                        model.add(Activation('relu'))\n",
    "                        model.add(Dropout(dropout_value))\n",
    "\n",
    "                    model.add(Dense(1))\n",
    "                    model.add(Activation('sigmoid'))\n",
    "\n",
    "                    model.compile(loss='binary_crossentropy',\n",
    "                      optimizer='adam',\n",
    "                      metrics=['accuracy', 'Precision'])\n",
    "\n",
    "                    # Training the model\n",
    "                    training = model.fit(X_train, y_train, batch_size = 32, epochs = 20, validation_split = 0.3, callbacks = [tensorboard_callback])\n",
    "                    evaluate_arr = model.evaluate(X_test , y_test , batch_size = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Sq86WsZ9VaZM"
   },
   "outputs": [],
   "source": [
    "# Load tensorboard webpage to monitor data\n",
    "%tensorboard --logdir 'logs/jaffe/'"
   ]
  }
 ],
 "metadata": {
  "accelerator": "TPU",
  "colab": {
   "collapsed_sections": [],
   "name": "assign2new.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
